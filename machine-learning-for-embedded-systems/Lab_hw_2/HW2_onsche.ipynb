{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b57c3c7-9e01-4892-b8f6-dd60c3077713",
   "metadata": {},
   "source": [
    "# Machine Learning for Embedded Systems\n",
    "## Home assignment 2 - training NN model built in Keras\n",
    "### OndÅ™ej Schejbal\n",
    "* Student code: 214308IV\n",
    "* UNI-ID: onsche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fe5b19a-9c4b-48d3-ad8f-6d5472c92b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "from matplotlib import pyplot\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow_model_optimization.python.core.quantization.keras import quantize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d23f22-2690-43ee-abe6-fed66c1615e5",
   "metadata": {},
   "source": [
    "### Load MNIST dataset, normalize values and show few images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c71bd6db-40a3-4012-a46a-26270984895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare MNIST dataset\n",
    "def loadMnistDataset():\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    (x_train, y_train) , (x_test, y_test) = mnist.load_data()\n",
    "    # Normalize\n",
    "    x_train = x_train / 255.0\n",
    "    x_test = x_test / 255.0\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1fa1ed5-c65f-4688-8663-0ffe824408d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = loadMnistDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca5f6d2d-ca69-4fac-ad96-630aa5cb1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
    "# print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n",
    "# # plot first few images from the dataset\n",
    "# for i in range(9):\n",
    "#     pyplot.subplot(330 + 1 + i)\n",
    "#     pyplot.imshow(x_train[i], cmap=pyplot.get_cmap('gray'))\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556870d4-d248-4487-99a8-9a00b441f6ea",
   "metadata": {},
   "source": [
    "## First we construct and run the initial NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f2f1eaf-3341-432d-9bc5-a2e9c59d8dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareInitialModel():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    # (dimensionality of the output space, activation)\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "    model.add(tf.keras.layers.Dense(80, activation='elu'))\n",
    "    model.add(tf.keras.layers.Dense(60, activation='elu'))\n",
    "    # Dropout layer randomly sets input units to 0 with a frequency of rate\n",
    "    #    at each step during training time, which helps prevent overfitting\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.Dense(10)) # empty activation == no activation fction\n",
    "    return model\n",
    "\n",
    "# modified model (for testing continuous steps)\n",
    "# def prepareInitialModel():\n",
    "#     model = tf.keras.models.Sequential()\n",
    "#     model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "#     # model.add(tf.keras.layers.Dense(80, activation='elu'))\n",
    "#     # model.add(tf.keras.layers.Dense(60, activation='elu'))\n",
    "#     model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "#     model.add(tf.keras.layers.Dropout(0.2))\n",
    "#     model.add(tf.keras.layers.Dense(10))\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33914685-cfd9-4d67-8fb6-69ec32fdfe7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 80)                62800     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 68,270\n",
      "Trainable params: 68,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initialModel = prepareInitialModel()\n",
    "initialModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f9f703f-5f84-44c2-b0c6-386d123471c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTotalParamsCountFromModelSummary(model, print_it=True):\n",
    "    paramsDetails = []\n",
    "    model.summary(print_fn=lambda x: paramsDetails.append(x))\n",
    "    paramsDetails = paramsDetails[-4].replace(\",\", \"\").split()\n",
    "    paramCount = [int(s) for s in paramsDetails if s.isdigit()]\n",
    "    if len(paramCount) > 1:\n",
    "        raise \"Unexpected length of paramCount\"\n",
    "    if print_it:\n",
    "        print('Total params:', paramCount[0])\n",
    "    return paramCount[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce658b1d-b217-43ce-86aa-63712fc79962",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics_arr = ['accuracy']\n",
    "learning_rate = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "253db7c0-2441-4221-a293-4f5dc575bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_initial = loss_fn(y_train[:1], predictions).numpy()\n",
    "# print('Untrained model inital loss: ' + str(loss_initial))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eab52b-e9f4-4a2b-991e-f5b05476ab85",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "febff9d4-ef9c-413e-b192-5f42fdb63ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitModel(x_train, y_train, model, optimizer, loss_fn, metrics_arr, epochs = 5, callbacks = None):\n",
    "    model.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics_arr)\n",
    "    model.fit(x_train, y_train, epochs=epochs, callbacks=callbacks)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a252625c-140c-49c6-842f-7e6c527dce01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3151 - accuracy: 0.9060\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1575 - accuracy: 0.9516\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1122 - accuracy: 0.9656\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0893 - accuracy: 0.9719\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0734 - accuracy: 0.9774\n"
     ]
    }
   ],
   "source": [
    "initialModel = fitModel(x_train, y_train, initialModel, optimizer, loss_fn, metrics_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97ad6ab0-2052-4079-b776-3e9aefafd0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundLossAndAccuracy(loss, accuracy, ndigits=5):\n",
    "    return round(loss, ndigits), round(accuracy, ndigits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb1b936f-aa00-4396-8fa5-011899af9a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0897 - accuracy: 0.9728\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "initialModel_loss, initialModel_accuracy = initialModel.evaluate(x_test, y_test)\n",
    "initialModel_loss, initialModel_accuracy = roundLossAndAccuracy(initialModel_loss, initialModel_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b097ddfc-d25c-4d74-830f-be9690325607",
   "metadata": {},
   "source": [
    "### Save model as tf Lite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f45765aa-534c-4abe-98c2-c2a40f9b1faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModelAsTFL(model, fileName):\n",
    "    # Convert the model\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    with open(fileName, 'wb') as f:\n",
    "        f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6da1e842-f78f-476c-8622-31e116618ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialModelPath = 'initialModel.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84d39116-ba77-4f89-adb5-7906717af07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\schejond\\AppData\\Local\\Temp\\tmpi54ao81d\\assets\n"
     ]
    }
   ],
   "source": [
    "saveModelAsTFL(initialModel, initialModelPath);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e21e86-3b04-4b24-9923-313c876493f5",
   "metadata": {},
   "source": [
    "## I have decided to focus on optimizing the memory size of the prepared model\n",
    "\n",
    "The target is to minimize the size of the model while also keeping the accuracy of the initial model as high as possible.\n",
    "\n",
    "The model memory size is the **total number of parameters of the model + it's memory allocation size in KB when saved as TensorFlow Lite model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e82111ae-443b-4c1e-80d8-ded58fd3f53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareMyModel():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "    \n",
    "    # # code for pruning only 1 specific layer\n",
    "    # mdl = tf.keras.layers.Dense(50, activation='relu')\n",
    "    # toAdd = tfmot.sparsity.keras.prune_low_magnitude(mdl)\n",
    "    # model.add(toAdd)\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.Dense(10))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a2ab387-1c78-49cf-ae6a-707cb24ca638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "myModel = prepareMyModel()\n",
    "myModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6270a667-72fb-4eb9-bb32-7c0171459c91",
   "metadata": {},
   "source": [
    "### Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1866d205-2672-4b9a-bb4b-71d30da93b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_model = False\n",
    "\n",
    "def apply_pruning_to_dense(layer):\n",
    "    # other layers for pruning can be also filtered here\n",
    "    if isinstance(layer, tf.keras.layers.Dense):\n",
    "        return tfmot.sparsity.keras.prune_low_magnitude(layer)\n",
    "    return layer\n",
    "\n",
    "if prune_model:\n",
    "    myModel = tf.keras.models.clone_model(myModel,\n",
    "                                          clone_function=apply_pruning_to_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6195007-cbfe-4dba-adb2-2d40d5b1fab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.5,\n",
    "                                                        final_sparsity=0.8,\n",
    "                                                        begin_step=0,\n",
    "                                                        end_step=np.ceil(np.int32(len(x_train / 32)) * 5))\n",
    "# pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.0, final_sparsity=0.5,\n",
    "#                                                         begin_step=2000, end_step=4000)\n",
    "\n",
    "# logdir = tempfile.mkdtemp() \n",
    "pruningCallbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  # tfmot.sparsity.keras.PruningSummaries(log_dir=logdir)\n",
    "]\n",
    "\n",
    "if prune_model:\n",
    "    myModel = tfmot.sparsity.keras.prune_low_magnitude(myModel, pruning_schedule=pruning_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98246d40-b66a-403a-846d-b88b11dc334e",
   "metadata": {},
   "source": [
    "#### QUANTIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9285ec76-eb8f-40ee-abad-2a6ae2674803",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize_model = True\n",
    "def applyQuantizationToSomeLayers(layer):\n",
    "    # here I experimented with only adding some type of layers\n",
    "    # if isinstance(layer, tf.keras.layers.Dense):\n",
    "    #     return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
    "    # return layer\n",
    "    return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
    "\n",
    "def quantizeModel(model, print_summary = True):\n",
    "    annotated_model = tf.keras.models.clone_model(model, clone_function=applyQuantizationToSomeLayers)\n",
    "    quantized_model = tfmot.quantization.keras.quantize_apply(annotated_model)\n",
    "    if print_summary:\n",
    "        quantized_model.summary()\n",
    "    return quantized_model\n",
    "    \n",
    "if quantize_model:\n",
    "    quantizeModel(myModel, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c2dbd16-c08a-4795-9066-aa9a2330d6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "metrics_arr = ['accuracy']\n",
    "learning_rate = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f67e773-c301-4b0e-8029-9ab09dc5e503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 0.3811 - accuracy: 0.8901: 0s - loss: 0.3848 - accuracy: 0. - ETA: 0s - loss: 0.3811 - accuracy: 0.89\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2039 - accuracy: 0.9385\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1702 - accuracy: 0.9493: 0s - loss: 0.1699 - accu\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1481 - accuracy: 0.9549\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1336 - accuracy: 0.9581\n"
     ]
    }
   ],
   "source": [
    "myModel = fitModel(x_train, y_train, myModel, optimizer, loss_fn, metrics_arr, 5, pruningCallbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c65719d0-1612-4245-b74e-7c70f476273b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1019 - accuracy: 0.9696\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance\n",
    "model_loss, model_accuracy = myModel.evaluate(x_test, y_test)\n",
    "model_loss, model_accuracy = roundLossAndAccuracy(model_loss, model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11b9f587-eaa7-46dc-95fc-a098c7f83148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to strip_pruning before saving\n",
    "if prune_model:\n",
    "    myModel = tfmot.sparsity.keras.strip_pruning(myModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da7f2bfb-47aa-4536-8c1e-0d6d8ea7d918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\schejond\\AppData\\Local\\Temp\\tmpb4jzcx4m\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\schejond\\AppData\\Local\\Temp\\tmpb4jzcx4m\\assets\n"
     ]
    }
   ],
   "source": [
    "myModelPath = 'myModel.tflite'\n",
    "saveModelAsTFL(myModel, myModelPath);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a58cdc5-2eb6-487d-a2e8-bbcd6ab9ec74",
   "metadata": {},
   "source": [
    "### Compare file size of initial model and the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6267b33f-cf17-404f-a510-455e3fbfa5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printModelMemorySize(model, modelPath):\n",
    "    print(getTotalParamsCountFromModelSummary(model, False), '+', os.stat(modelPath).st_size/1024, 'KB');\n",
    "    print('Total model size:', getTotalParamsCountFromModelSummary(model, False) + os.stat(modelPath).st_size/1024, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "810aa9d3-5c17-4bbe-88c9-2886f6af3d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Initial model stats:\n",
      "\n",
      "68270 + 71.125 KB\n",
      "Total model size: 68341.125 \n",
      "\n",
      "Model loss: 0.08969 Model prediction accuracy: 0.9728\n",
      "---------------------------------------------------------\n",
      "My model stats:\n",
      "\n",
      "39760 + 42.078125 KB\n",
      "Total model size: 39802.078125 \n",
      "\n",
      "Model loss: 0.10195 Model prediction accuracy: 0.9696\n",
      "---------------------------------------------------------\n",
      "Model with better accuracy: initialModel 0.0032\n",
      "Model with less weight: myModel 28539.0469\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------')\n",
    "print('Initial model stats:\\n')\n",
    "printModelMemorySize(initialModel, initialModelPath)\n",
    "print('Model loss:', initialModel_loss, 'Model prediction accuracy:', initialModel_accuracy)\n",
    "print('---------------------------------------------------------')\n",
    "print('My model stats:\\n')\n",
    "printModelMemorySize(myModel, myModelPath)\n",
    "print('Model loss:', model_loss, 'Model prediction accuracy:', model_accuracy)\n",
    "print('---------------------------------------------------------')\n",
    "print('Model with better accuracy:',\n",
    "      'myModel' if model_accuracy > initialModel_accuracy else 'initialModel', round(abs(model_accuracy - initialModel_accuracy),4))\n",
    "myModelWeight = getTotalParamsCountFromModelSummary(myModel, False) + os.stat(myModelPath).st_size/1024\n",
    "initialModelWeight = getTotalParamsCountFromModelSummary(initialModel, False) + os.stat(initialModelPath).st_size/1024\n",
    "print('Model with less weight:',\n",
    "      'myModel' if myModelWeight < initialModelWeight else 'initialModel', round(abs(myModelWeight - initialModelWeight), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61891d0-fde4-4212-bc4c-00035c4cab67",
   "metadata": {},
   "source": [
    "### Accuracy on my own data\n",
    "\n",
    "I have prepared my own handwritten numbers 0-9\n",
    "\n",
    "In the cells below I have evaluated them on my final model and shown the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c37b123e-800a-45b3-bbf8-007fafb56c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "173cfab7-45d2-4489-b104-7e78ef1b5c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images to features and labels\n",
    "def load_images_to_data(x_data, y_data):\n",
    "    list_of_files = os.listdir(\"MyNumbers\")\n",
    "    for file in list_of_files:\n",
    "        image_file_name = os.path.join(\"MyNumbers\", file)\n",
    "        if \".png\" in image_file_name:\n",
    "            img = Image.open(image_file_name).convert(\"L\")\n",
    "            img = np.resize(img, (28,28))\n",
    "            im2arr = np.array(img)\n",
    "            im2arr = im2arr.reshape(1,28,28)\n",
    "            \n",
    "            if len(x_data) == 0:\n",
    "                x_data = im2arr\n",
    "            else:\n",
    "                x_data = np.append(x_data, im2arr, axis=0)\n",
    "            \n",
    "            if len(y_data) == 0:\n",
    "                y_data = [np.uint8(file[0])]\n",
    "            else:\n",
    "                y_data = np.append(y_data, [np.uint8(file[0])], axis=0)\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7344e59-d588-44e9-bbb3-e6b53439366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_my = []\n",
    "y_test_my = []\n",
    "\n",
    "x_test_my, y_test_my = load_images_to_data(x_test_my, y_test_my)\n",
    "\n",
    "x_test_my = x_test_my / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dee19805-a4ea-4942-a941-89ae6673aa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step - loss: 5.4950 - accuracy: 0.2000\n"
     ]
    }
   ],
   "source": [
    "# evaluate my final model's performance on my handwritten numbers\n",
    "myModel.evaluate(x_test_my, y_test_my);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8ea40cd-39ce-43fb-90cc-f233e867dfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step - loss: 8.6413 - accuracy: 0.2000\n"
     ]
    }
   ],
   "source": [
    "initialModel.evaluate(x_test_my, y_test_my);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e691ae3d-4c39-415a-9461-4085d1dadef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
